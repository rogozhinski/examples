{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5e502fe-3cd2-4e53-93bd-8ca279b0aa98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, \\\n",
    "                            f1_score, precision_recall_curve, PrecisionRecallDisplay,\\\n",
    "                            roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import Sigmoid, Module, BCELoss, Linear, ReLU\n",
    "from torch.optim import Adam\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import onnxruntime as ort\n",
    "import onnx\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a089872-5dc8-4dd7-b616-13c3c7a0332e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, image_metadata, labels, session, mode='valid'):\n",
    "        self.image_metadata = image_metadata\n",
    "        self.labels = labels\n",
    "        self.mode = mode\n",
    "        self.random_transform = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(p=0.5)\n",
    "        ])\n",
    "        self.input_mean = 127.5\n",
    "        self.input_std = 1 / 127.5\n",
    "        self.ort_session = session\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = cv2.imread(self.image_metadata[idx])\n",
    "        prepared_tensor = cv2.dnn.blobFromImage(image, self.input_std, (112, 112), self.input_mean, swapRB=True)\n",
    "        prepared_tensor = torch.tensor(self.ort_session.run(None, {'input': prepared_tensor})[0])\n",
    "        return prepared_tensor, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "117eef1a-fe4c-46d3-9564-64503c403f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_discriptions = np.loadtxt('/workspace/db/All-Age-Faces Dataset/annotation_train.txt', delimiter=',', dtype=str)\n",
    "train_discriptions = pd.DataFrame(train_discriptions, columns=['image_name', 'sex']).set_index('image_name')\n",
    "\n",
    "train_images_list = np.array(os.listdir('/workspace/db/All-Age-Faces Dataset/train'), dtype=str)\n",
    "train_images_list = pd.DataFrame(train_images_list, columns=['image_name']).set_index('image_name')\n",
    "\n",
    "train_discriptions = train_discriptions.join(train_images_list, on='image_name', how='inner')\n",
    "train_labels = torch.tensor(train_discriptions['sex'].astype(int)[:, None], dtype=torch.int8)\n",
    "train_image_metadata = np.char.add('/workspace/db/All-Age-Faces Dataset/train/', train_discriptions.index.to_numpy(dtype='<U60'))\n",
    "\n",
    "\n",
    "val_discriptions = np.loadtxt('/workspace/db/All-Age-Faces Dataset/annotation_val.txt', delimiter=',', dtype=str)\n",
    "valid_labels = torch.tensor(val_discriptions[:, 1, None].astype(int), dtype=torch.int8)\n",
    "valid_image_metadata = np.char.add('/workspace/db/All-Age-Faces Dataset/val/', val_discriptions[:, 0])\n",
    "\n",
    "test_discriptions = np.loadtxt('/workspace/db/All-Age-Faces Dataset/annotation_test.txt', delimiter=',', dtype=str)\n",
    "test_labels = torch.tensor(test_discriptions[:, 1, None].astype(int), dtype=torch.int8)\n",
    "test_image_metadata = np.char.add('/workspace/db/All-Age-Faces Dataset/test/', test_discriptions[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db314cdb-7cd4-44d2-94a7-05a8c8ea802a",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = ort.InferenceSession('hjj_ea_e37_p20.onnx')\n",
    "\n",
    "#load training dataset\n",
    "train_dataset = FaceDataset(image_metadata=train_image_metadata, labels=train_labels, session=session, mode='train')\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=32, num_workers=16, shuffle=True)\n",
    "\n",
    "#load valid dataset\n",
    "valid_dataset = FaceDataset(image_metadata=valid_image_metadata, labels=valid_labels, session=session, mode='valid')\n",
    "valid_dataloader = DataLoader(dataset=valid_dataset, batch_size=32, num_workers=16, shuffle=False)\n",
    "\n",
    "#load test dataset\n",
    "test_dataset = FaceDataset(image_metadata=test_image_metadata, labels=test_labels, session=session, mode='valid')\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=32, num_workers=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9d39c94-8c89-4931-853f-baba0ed3107c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpdatedModel(Module):\n",
    "    # this class adds sigmoid activation at the end of a net\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(UpdatedModel, self).__init__()\n",
    "        # changes output dim of final FC-layer from 1000 to 1\n",
    "        self.fc1 = Linear(in_features=512, out_features=256) \n",
    "        self.relu = ReLU()\n",
    "        self.fc2 = Linear(in_features=256, out_features=1) \n",
    "        \n",
    "        # add sigmoid activation at the end of a net\n",
    "        self.sigmoid = Sigmoid()\n",
    "        \n",
    "        # here we also can change model in some other way, e. freeze some layers\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b26faec-120b-4d62-82b9-e13d0ce1709d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelWrapper():\n",
    "    \n",
    "    def __init__(self, model): \n",
    "        self.model = model\n",
    "        self.optimizer = Adam(self.model.parameters(), lr=0.001)\n",
    "        self.loss_function = BCELoss()\n",
    "        self.model.to(device)\n",
    "    \n",
    "    def fit(self, train_dataloader, valid_dataloader, \n",
    "            max_epoch_num=1e3, epoch_num_early_stopping=10, print_each_nth_epoch=10):\n",
    "        \n",
    "        # epoch_num_early_stopping = number of epochs \n",
    "        # that didn't decrease the best loss of epoch (min_epoch_loss)\n",
    "        \n",
    "        epoch_array = np.empty((0))\n",
    "        train_loss_array = np.empty((0))\n",
    "        valid_loss_array = np.empty((0))\n",
    "    \n",
    "        epoch = 1\n",
    "        \n",
    "        min_epoch_loss = np.inf\n",
    "        epoch_num_without_imporovement = 0\n",
    "        \n",
    "        cur_epoch_time = time.time()\n",
    "        \n",
    "        # training by epochs\n",
    "        while epoch <= max_epoch_num and epoch_num_without_imporovement<=epoch_num_early_stopping:\n",
    "            \n",
    "            train_epoch_loss = 0\n",
    "            valid_epoch_loss = 0\n",
    "#             cur_batch_time = time.time()\n",
    "            # batch-wise training within an epoch\n",
    "            for batch, (x, y) in enumerate(train_dataloader):\n",
    "\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                \n",
    "                # straightforward move\n",
    "                output = self.model(x)[:,0]\n",
    "                loss = self.loss_function(output, y.float())\n",
    "                train_epoch_loss =+ loss.item() / (batch + 1)\n",
    "                \n",
    "                print_each_nth_batch = 10\n",
    "                if batch%print_each_nth_batch==0:\n",
    "                    print('batch #', batch, \n",
    "                          '   |   train_batch_loss:', loss.item(), \n",
    "                         '   |   ', print_each_nth_batch, ' batches of ', train_dataloader.batch_size, \n",
    "                          ' samples took', np.round(time.time() - cur_batch_time), ' s')\n",
    "                    cur_batch_time = time.time()\n",
    "                \n",
    "                # backpropagation\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "            valid_epoch_loss = self.validation_loss(valid_dataloader, valid_data_size)\n",
    "            \n",
    "            epoch_array = np.append(epoch_array, epoch)\n",
    "            train_loss_array = np.append(train_loss_array, train_epoch_loss)\n",
    "            valid_loss_array = np.append(valid_loss_array, valid_epoch_loss)\n",
    "            \n",
    "            # prints losses every x epochs\n",
    "            if epoch%print_each_nth_epoch==0:\n",
    "                print('epoch ', epoch, \n",
    "                      '   |   train_epoch_loss:', train_epoch_loss, \n",
    "                      '   |   valid_epoch_loss:', valid_epoch_loss, \n",
    "                     '   |   ', print_each_nth_epoch, ' epochs took', np.round(time.time() - cur_epoch_time), ' s')\n",
    "                cur_epoch_time = time.time()\n",
    "\n",
    "            # increases num of epochs without decrease of validation loss        \n",
    "            if valid_epoch_loss > min_epoch_loss: \n",
    "                epoch_num_without_imporovement += 1\n",
    "            else: \n",
    "                min_epoch_loss = valid_epoch_loss\n",
    "                epoch_num_without_imporovement = 0\n",
    "                \n",
    "            epoch += 1\n",
    "            \n",
    "        return epoch_array, train_loss_array, valid_loss_array\n",
    "    \n",
    "    def validation_loss(self, valid_dataloader, valid_data_size):\n",
    "        with torch.no_grad():\n",
    "            valid_loss = 0\n",
    "            for batch, (x, y) in enumerate(valid_dataloader):\n",
    "                \n",
    "                x, y = x.to(device), y.to(device)\n",
    "                \n",
    "                output = self.model(x)[:,0]\n",
    "                valid_loss += self.loss_function(output, y.float()).item() / (batch + 1)\n",
    "            return valid_loss\n",
    "    \n",
    "    def predict_proba(self, dataloader):\n",
    "        with torch.no_grad():\n",
    "            prediction_array = np.empty((0))\n",
    "            for batch, (x, y) in enumerate(dataloader):\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                output = self.model(x)[:,0]\n",
    "                prediction_array = np.append(prediction_array, output.cpu().numpy().flatten())               \n",
    "            return prediction_array\n",
    "    \n",
    "    def predict(self, dataloader):\n",
    "        return np.round(self.predict_proba(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b785b19a-1e57-42f0-8203-953cfe9defd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_model = UpdatedModel()\n",
    "model_wrapper = ModelWrapper(updated_model)\n",
    "epoch_array, train_loss_array, valid_loss_array = model_wrapper.fit(\n",
    "                train_dataloader=train_dataloader, \n",
    "                  valid_dataloader=valid_dataloader,\n",
    "                 max_epoch_num=1, \n",
    "                 epoch_num_early_stopping=5,\n",
    "                print_each_nth_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da253428-7395-4411-9bc1-78abaa7db01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_proba = model_wrapper.predict_proba(test_dataloader)\n",
    "prediction = np.round(prediction_proba)\n",
    "y_true = test_dataset.labels.numpy()\n",
    "\n",
    "print(prediction_proba)\n",
    "print(prediction)\n",
    "\n",
    "print('accuracy_score: ', accuracy_score(y_true, prediction))\n",
    "print('precision_score: ', precision_score(y_true, prediction))\n",
    "print('recall_score: ', recall_score(y_true, prediction))\n",
    "print('f1_score: ', f1_score(y_true, prediction))\n",
    "print('roc_auc_score: ', roc_auc_score(y_true, prediction))\n",
    "\n",
    "def plot_auc_roc (precision, recall):\n",
    "\n",
    "    fig = plt.figure(num=1, figsize=(18,6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(recall, precision, color='tab:red', label='ROC curve')\n",
    "    ax.set_xlabel('recall')\n",
    "    ax.set_ylabel('prcision')\n",
    "    ax.xaxis.label.set_color('white')\n",
    "    ax.yaxis.label.set_color('white')\n",
    "    ax.tick_params(axis='x', colors='white')\n",
    "    ax.tick_params(axis='y', colors='white')\n",
    "    legend = ax.legend(loc='upper right', shadow=True, fontsize='x-large')\n",
    "    plt.show()\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_true, prediction_proba)\n",
    "plot_auc_roc (precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b523a74-3b43-4ba4-b5e7-7c8f4a83cbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scripted = torch.jit.script(model_wrapper.model)\n",
    "model_scripted.save('./saved/samsung_model_scripted_all-age-faces.pt') \n",
    "torch.save(model_wrapper.model, './saved/samsung_model_all-age-faces.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9406a58b-a005-473f-b744-1169f1a8726e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# выведем примеры ошибок (нераспознанные мужчины)\n",
    "\n",
    "male_faults = test_dataset.image_metadata[np.logical_and(y_true.flatten()!=prediction.flatten(), (y_true==1).flatten())]\n",
    "random_male_faults = np.random.choice(male_faults, size=20, replace=False)\n",
    "w = 10\n",
    "h = 10\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "columns = 4\n",
    "rows = 5\n",
    "for i in range(1, 20+1):\n",
    "    print(random_male_faults[i-1])\n",
    "    img = Image.open(random_male_faults[i-1])\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e99089e-dee9-4c8b-9ffe-7000639a2527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# выведем примеры ошибок (нераспознанные женщины)\n",
    "\n",
    "female_faults = test_dataset.image_metadata[np.logical_and(y_true.flatten()!=prediction.flatten(), (y_true==0).flatten())]\n",
    "random_female_faults = np.random.choice(female_faults, size=15, replace=False)\n",
    "w = 10\n",
    "h = 10\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "columns = 4\n",
    "rows = 5\n",
    "for i in range(1, 20+1):\n",
    "    img = Image.open(random_female_faults[i-1])\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55223e6-77d3-4804-a690-67ece41cc10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch = torch.empty((0, 512))\n",
    "np.random.seed(42)\n",
    "for item in np.random.randint(low=0, high=test_dataset.labels.shape[0], size=20):\n",
    "    test_batch = torch.cat([test_batch, test_dataset[item][0]], dim=0)\n",
    "\n",
    "test_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93a9362-8266-4fc2-9e8b-f77ef896ef11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
